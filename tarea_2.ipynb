{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes:\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones\n",
    "- Descargue el notebook y responda las preguntas dentro de este.\n",
    "- Entregue el notebook con todas las celdas ejecutadas.\n",
    "- Para dudas contactar a Javier Welch (welch.javier@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Comparación de Modelos de Clasificación (50%)\n",
    "\n",
    "En esta pregunta trabajará con un dataset de información relacionada a sesiones de usuario en un eCommerce y tratará de predecir si un usuario compró o no en el sitio. El dataset se encuentra disponible en el [Drive del curso](https://drive.google.com/drive/folders/1Ykcp3zXpc14asGwPD8NW0IWU3IZHjk5o) con el nombre \"online_shoppers.csv\"\n",
    "\n",
    "Variables:\n",
    "\n",
    "- \"Revenue\" indica si la sesión estuvo asociada a una compra.\n",
    "- \"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" y \"Product Related Duration\" representan el número de páginas de distintas categorías que visitó el usuario y el tiempo que estuvo en ellas. \n",
    "- Las features \"Bounce Rate\", \"Exit Rate\" y \"Page Value\" representan metricas de Google Analytics para cada página del eCommerce. El valor de \"Bounce Rate\" para una página se refiere al porcentaje de visitantes que entran al sitio y se van sin tener ninguna otra interacción con el sitio. El valor del \"Exit Rate\" se calcula para cada página como el porcentaje de las sesiones cuya última página visitada fue esa. La variable \"Page Value\" representa el valor promedio para una página que el usuario visitó antes de completar una transacción.\n",
    "- La variable \"Special Day\" representa la cercanía de la visita al sitio con una fecha especial (ej: Día de San Valentín, Día de la Madre, etc). El valor de este atributo se determina considerando las dinámicas del eCommerce como el tiempo entre la compra y la entrega del producto. Por ejemplo, para el Día de San Valentín, la variable toma valores distintos de cero entre el 2 y el 12 de Febrero y alcanza su máximo valor de 1 el día 8 de Febrero. \n",
    "- El dataset también incluye variables categóricas de sistema operativo, navegador, región, tipo de tráfico, tipo de visitante (nuevo o recurrente), indicador de si la visita fue en un fin de semana y el mes del año."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Importe las librerías que usará en su tarea.\n",
    "Esta pregunta no tiene puntaje, pero sí puede restar puntaje si importa librerías que no usa en su tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importe el dataset como un DataFrame (df) directamente desde Github (es decir, no descargue el archivo manualmente). A lo largo de la tarea este df se denominará como \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realice un EDA del dataset importado. Sea explícito en detallar cada paso que realiza. Como mínimo es necesario que grafique y analice la distribución de las variables. ¿Cómo se distribuye su variable target? ¿Está el dataset balanceado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Realice el preprocesamiento necesario para poder entregar todas las features a un modelo de clasificación (OneHotEncoding, imputación de missings, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Separe los datos en un dataset de entrenamiento y de testeo. ¿Por qué es importante la decisión del tamaño del dataset de testeo? Explique. Recuerde que sus resultados deben ser reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Entrene dos modelos de Clasificación: un Árbol de Decisión y una Regresión Logística. Compare los modelos en cuanto a sus métricas de desempeño: Accuracy, Precision, Recall y F1-Score. Además, si corresponde, muestre la matriz de confusión y la curva ROC-AUC de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Dada la naturaleza del problema y las características del dataset, ¿qué métrica de performance es la más apropiada para evaluar sus modelos? ¿Por qué? ¿Cuál sería el mejor modelo según esta métrica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Considere ahora solo el modelo de Árbol de Decisión: ¿Cómo afecta a las métricas de performance si varía la profundidad del árbol? Pruébelo con al menos 3 profundidades distintas y compare sus resultados. ¿Qué puede explicar este cambio en las métricas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering y PCA (50%)\n",
    "\n",
    "En esta pregunta trabajará con datos de la [Financial Access Survey (FAS)](https://data.imf.org/?sk=e5dcab7e-a5ca-4892-a6ea-598b5463a34c) de 2020 del Fondo Monetario Internacional (IMF). El dataset está disponible en el [Drive del curso](https://drive.google.com/drive/folders/1Ykcp3zXpc14asGwPD8NW0IWU3IZHjk5o) con el nombre \"FAS.csv\".\n",
    "\n",
    "Variables:\n",
    "- Country\n",
    "- Number of ATMs per 100,000 adults\n",
    "- Number of depositors with commercial banks per 1,000 adults\n",
    "- Number of borrowers from commercial banks per 1,000 adults\n",
    "- Outstanding deposits with commercial banks (% of GDP)\n",
    "- Outstanding loans from commercial banks (% of GDP)\n",
    "- Number of credit cards per 1,000 adults\n",
    "- Number of debit cards per 1,000 adults\n",
    "- Number of Non-life insurance policies per 1,000 adults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Importe las librerías que usará en su tarea.\n",
    "\n",
    "Esta pregunta no tiene puntaje, pero sí puede restar puntaje si importa librerías que no usa en su tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importe el dataset como un DataFrame (df) directamente desde Google Drive (es decir, no descargue el archivo manualmente). A lo largo de la tarea este df se denominará como \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Analice descriptivamente las variables del dataset y grafique su distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Reemplace los missing values de cada columna con el valor promedio de dicha columna y setee como índice del DataFrame la columna 'Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Realice un modelo k-means con las variables \"Number of credit cards per 1.000 adults\" y \"Number of debit cards per 1.000 adults\". Grafique con un scatter plot las variables antes mencionadas y, a partir de la clasificación realizada con el modelo, coloree con diferentes colores las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Considerando las mismas variables, utilice el método de Elbow para determinar el número de clusters óptimo. Explique y apoye su respuesta con el gráfico de la curva de Elbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Repita la pregunta 4 pero esta vez utilizando el número óptimo de clusters encontrado en la pregunta 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Describa el comportamiento promedio de cada uno de sus clusters. ¿Qué tipos de países se encuentran en cada uno? ¿Qué nombre le pondría a cada cluster o qué los caracteriza?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ¿Cómo afectaron sus resultados de la pregunta anterior la decisión de imputar los missing values usando el promedio de cada columna? ¿Cómo podría usar el algoritmo de k-means para poder imputar los datos faltantes (Recuerde que tiene más variables en su dataset)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Realice un PCA para reducir la dimensionalidad del dataset completo a solo 2 features. ¿Qué nombre le pondría a cada una de las features nuevas dadas sus componentes? ¿Cuánta varianza está perdiendo al reducir la dimensionalidad del problema? Dado esto, comente sobre la conveniencia de aplicar la reducción de dimensionalidad a este problema específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Repita lo realizado en la pregunta 4 utilizando las dos componentes principales recién estimadas. ¿Qué tipos de países quedan en cada cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
